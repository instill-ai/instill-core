name: e2e-test

on:
  schedule:
    - cron: "* 2 * * *"

jobs:
  pipeline-on-prem:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout (latest)
        uses: actions/checkout@v2

      - name: Load .env file
        uses: cardinalby/export-env-action@v2
        with:
          envFile: .env
          expand: true

      - uses: actions/setup-go@v3
        with:
          go-version: ${{ env.GOLANG_VERSION }}

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2

      # mono occupies port 8084 which conflicts with mgmt-backend
      - name: Stop mono service
        run: |
          sudo kill -9 `sudo lsof -t -i:8084`
          sudo lsof -i -P -n | grep LISTEN

      - name: Free disk space
        run: |
          df --human-readable
          sudo apt clean
          docker rmi $(docker image ls --all --quiet) > /dev/null || true
          rm --recursive --force "$AGENT_TOOLSDIRECTORY" > /dev/null || true
          df --human-readable

      - name: Launch VDP (latest)
        run: |
          COMPOSE_PROFILES=all \
          EDITION=local-ce:test \
          ITMODE=false \
          TRITON_CONDA_ENV_PLATFORM=cpu \
          docker compose -f docker-compose.yml -f docker-compose.dev.yml up -d --quiet-pull
          COMPOSE_PROFILES=all \
          docker compose -f docker-compose.yml -f docker-compose.dev.yml rm -f

      - name: Install k6
        run: |
          curl https://github.com/grafana/k6/releases/download/v${{ env.K6_VERSION }}/k6-v${{ env.K6_VERSION }}-linux-amd64.tar.gz -L | tar xvz --strip-components 1 && sudo cp k6 /usr/bin

      - name: Inference mobilenetv2 model
        run: |
          cd ./test; make pipeline-mobilenetv2 MODE=localhost TEST_CPU_ONLY=true

      - name: Inference yolov7 model
        run: |
          cd ./test; make pipeline-yolov7 MODE=localhost TEST_CPU_ONLY=true

      - name: Inference instance segmentation model
        run: |
          cd ./test; make pipeline-instance-segmentation MODE=localhost TEST_CPU_ONLY=true

      - name: Inference semantic segmentation model
        run: |
          cd ./test; make pipeline-semantic-segmentation MODE=localhost TEST_CPU_ONLY=true

      - name: Inference text to image model
        run: |
          cd ./test; make pipeline-text-to-image MODE=localhost TEST_CPU_ONLY=true
